{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pip install yfinance --upgrade --no-cache-dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T06:09:41.215216Z",
     "iopub.status.busy": "2025-03-28T06:09:41.214801Z",
     "iopub.status.idle": "2025-03-28T06:09:41.220582Z",
     "shell.execute_reply": "2025-03-28T06:09:41.219166Z",
     "shell.execute_reply.started": "2025-03-28T06:09:41.215180Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch Stock Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T06:09:42.020683Z",
     "iopub.status.busy": "2025-03-28T06:09:42.020272Z",
     "iopub.status.idle": "2025-03-28T06:09:42.028655Z",
     "shell.execute_reply": "2025-03-28T06:09:42.027414Z",
     "shell.execute_reply.started": "2025-03-28T06:09:42.020648Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# top 50-100 publicly traded companies\n",
    "sp50_tickers = [\n",
    "    'AAPL', 'ABBV', 'ABT', 'ACN', 'ADBE', 'AIG', 'AMD', 'AMGN', 'AMT', 'AMZN',\n",
    "    'AVGO', 'AXP', 'BA', 'BAC', 'BK', 'BKNG', 'BLK', 'BRK.B', 'C',\n",
    "    'CAT', 'CHTR', 'CL', 'CMCSA', 'COF', 'COP', 'COST', 'CRM', 'CSCO', 'CVS',\n",
    "    'CVX', 'DE', 'DHR', 'DIS', 'DOW', 'DUK', 'EMR', 'F', 'FDX', 'GD', 'GE',\n",
    "    'GILD', 'GM', 'GOOG', 'GOOGL', 'GS', 'HD', 'HON', 'IBM', 'INTC', 'INTU',\n",
    "    'JNJ', 'JPM', 'KHC', 'KO', 'LIN', 'LLY', 'LMT', 'LOW', 'MA', 'MCD',\n",
    "    'MDLZ', 'MDT', 'MET', 'META', 'MMM', 'MO', 'MRK', 'MS', 'MSFT', 'NEE',\n",
    "    'NFLX', 'NKE', 'NVDA', 'ORCL', 'PEP', 'PFE', 'PG', 'PM', 'PYPL', 'QCOM',\n",
    "    'RTX', 'SBUX', 'SCHW', 'SO', 'SPG', 'T', 'TGT', 'TMO', 'TMUS', 'TSLA',\n",
    "    'TXN', 'UNH', 'UNP', 'UPS', 'USB', 'V', 'VZ', 'WFC', 'WMT', 'XOM'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T06:09:43.525340Z",
     "iopub.status.busy": "2025-03-28T06:09:43.524964Z",
     "iopub.status.idle": "2025-03-28T06:09:43.530629Z",
     "shell.execute_reply": "2025-03-28T06:09:43.529431Z",
     "shell.execute_reply.started": "2025-03-28T06:09:43.525307Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Indexes helpful to predict stock, key is API symbol for each index\n",
    "indicators = {\"^IXIC\": \"NASDAQ\", \n",
    "              \"^GSPC\": \"SNP\", \n",
    "              \"^DJI\": \"DJI\", \n",
    "              \"^RUT\": \"RUT\", \n",
    "              \"^VIX\": \"VIX\", \n",
    "              \"XLK\": \"XLK\",\n",
    "              \"XLE\": \"XLE\",\n",
    "              \"XLF\": \"XLF\",\n",
    "              \"XLV\": \"XLV\"\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T06:09:45.860474Z",
     "iopub.status.busy": "2025-03-28T06:09:45.860148Z",
     "iopub.status.idle": "2025-03-28T06:09:47.174760Z",
     "shell.execute_reply": "2025-03-28T06:09:47.173204Z",
     "shell.execute_reply.started": "2025-03-28T06:09:45.860450Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create dataframe of important stock index\n",
    "indicator_df = None\n",
    "for symbol in indicators:\n",
    "    ticker = yf.Ticker(symbol)\n",
    "    stock_df = ticker.history(period='10y', interval='1d').reset_index()\n",
    "    stock_df.head()\n",
    "    stock_df = stock_df.rename(columns={\n",
    "        'Open': indicators[symbol]\n",
    "    })\n",
    "    stock_df = stock_df[['Date', indicators[symbol]]]\n",
    "    stock_df['Date'] = stock_df['Date'].dt.date\n",
    "    \n",
    "    if indicator_df is None:\n",
    "        indicator_df = stock_df.copy()\n",
    "        continue\n",
    "    indicator_df = indicator_df.merge(stock_df, how='inner', on=['Date'])\n",
    "indicator_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T06:14:31.535352Z",
     "iopub.status.busy": "2025-03-28T06:14:31.534975Z",
     "iopub.status.idle": "2025-03-28T06:14:31.542325Z",
     "shell.execute_reply": "2025-03-28T06:14:31.540870Z",
     "shell.execute_reply.started": "2025-03-28T06:14:31.535325Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ================================\n",
    "# ðŸ“Œ Load and Process Stock Data\n",
    "# ================================\n",
    "def load_stock_data(ticker_symbol, indicators=indicator_df):\n",
    "    \"\"\"Fetches stock data from Yahoo Finance and processes it for merging.\"\"\"\n",
    "    print(f\"loading {ticker_symbol}\")\n",
    "    ticker = yf.Ticker(ticker_symbol)\n",
    "    stock_df = ticker.history(period='10y', interval='1d').reset_index()\n",
    "    try:\n",
    "        stock_df['month'] = stock_df['Date'].dt.month\n",
    "        stock_df['day'] = stock_df['Date'].dt.day\n",
    "        stock_df['day_of_week'] = stock_df['Date'].dt.dayofweek\n",
    "        stock_df['Date'] = stock_df['Date'].dt.date\n",
    "        stock_df = stock_df.merge(indicators, how='left', on=['Date'])\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        stock_df = None\n",
    "    return stock_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T06:14:37.745149Z",
     "iopub.status.busy": "2025-03-28T06:14:37.744773Z",
     "iopub.status.idle": "2025-03-28T06:14:38.001710Z",
     "shell.execute_reply": "2025-03-28T06:14:38.000477Z",
     "shell.execute_reply.started": "2025-03-28T06:14:37.745120Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test = load_stock_data('AAPL')\n",
    "test.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T06:15:05.095287Z",
     "iopub.status.busy": "2025-03-28T06:15:05.094929Z",
     "iopub.status.idle": "2025-03-28T06:15:05.111049Z",
     "shell.execute_reply": "2025-03-28T06:15:05.109657Z",
     "shell.execute_reply.started": "2025-03-28T06:15:05.095259Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Embedding, Input, Concatenate\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=RuntimeWarning)\n",
    "\n",
    "# ================================\n",
    "# ðŸ“Œ Load and Process Sentiment Data\n",
    "# ================================\n",
    "def load_sentiment_data(file_path):\n",
    "    \"\"\"Loads and processes sentiment data, aggregates sentiment scores by date.\"\"\"\n",
    "    sentiment_map = {'positive': 1, 'neutral': 0, 'negative': -1}\n",
    "    \n",
    "    df = pd.read_csv(file_path)\n",
    "    df['sentiment_mapped'] = df['sentiment'].map(sentiment_map)\n",
    "    df['Date'] = pd.to_datetime(df['Date']).dt.date  # Convert to date (no time)\n",
    "\n",
    "    # Aggregate sentiment scores by date\n",
    "    sentiment_sum = df.groupby('Date', as_index=False)['sentiment_mapped'].sum()\n",
    "    sentiment_count = df.groupby('Date', as_index=False)['sentiment_mapped'].count()\n",
    "    sentiment_sum['sentiment'] = sentiment_sum['sentiment_mapped'] / sentiment_count['sentiment_mapped']\n",
    "\n",
    "    return sentiment_sum[['Date', 'sentiment']]\n",
    "\n",
    "# ================================\n",
    "# ðŸ“Œ Compute Technical Indicators\n",
    "# ================================\n",
    "def calculate_technical_indicators(df):\n",
    "    \"\"\"Computes RSI, Moving Averages, Log Returns, and Realized Volatility.\"\"\"\n",
    "    def calculate_rsi(data, column='Close', period=14):\n",
    "        delta = data[column].diff()\n",
    "        gains = delta.where(delta > 0, 0)\n",
    "        losses = -delta.where(delta < 0, 0)\n",
    "        avg_gain = gains.rolling(window=period, min_periods=1).mean()\n",
    "        avg_loss = losses.rolling(window=period, min_periods=1).mean()\n",
    "        rs = avg_gain / avg_loss\n",
    "        return 100 - (100 / (1 + rs))\n",
    "\n",
    "    df['RSI'] = calculate_rsi(df, column='Close')\n",
    "\n",
    "    # Moving Averages\n",
    "    for ma in [20, 50, 200]:\n",
    "        df[f'MA_{ma}'] = df['Close'].rolling(window=ma).mean()\n",
    "    \n",
    "    # Log Returns\n",
    "    df['log_return'] = np.log(df['Close'] / df['Close'].shift(1))\n",
    "\n",
    "    # Realized Volatility\n",
    "    for rv in [20, 50]:\n",
    "        df[f'RV_{rv}'] = df['log_return'].rolling(window=rv).std() * np.sqrt(252)\n",
    "    \n",
    "    return df  # Drop NaN values from rolling calculations\n",
    "\n",
    "# ================================\n",
    "# ðŸ“Œ Create time step\n",
    "# ================================\n",
    "def add_time_step_from_date(df, date_column='Date', step_column='time_idx'):\n",
    "    \"\"\"\n",
    "    Adds a TimeStep column to the DataFrame where each unique date gets\n",
    "    a unique, increasing integer starting from 0. Duplicate dates share the same time step.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): Input DataFrame with a date column.\n",
    "    - date_column (str): Name of the date column.\n",
    "    - step_column (str): Name of the time step column to add.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame with an added time step column.\n",
    "    \"\"\"\n",
    "    df[date_column] = pd.to_datetime(df[date_column])\n",
    "    unique_dates = pd.Series(df[date_column].sort_values().unique())\n",
    "    date_to_step = {date: i for i, date in enumerate(unique_dates)}\n",
    "    df[step_column] = df[date_column].map(date_to_step)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T06:15:08.885541Z",
     "iopub.status.busy": "2025-03-28T06:15:08.885203Z",
     "iopub.status.idle": "2025-03-28T06:15:36.412860Z",
     "shell.execute_reply": "2025-03-28T06:15:36.411736Z",
     "shell.execute_reply.started": "2025-03-28T06:15:08.885513Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ================================\n",
    "# ðŸ“Œ Main Processing for Multiple Stocks\n",
    "# ================================\n",
    "merged_dfs = []\n",
    "\n",
    "for stock in sp50_tickers:\n",
    "    path = \"/\" + stock + \".csv\"\n",
    "    path2 = \"/\" + stock + \".csv\"\n",
    "    try:\n",
    "        # Load sentiment and stock data\n",
    "        sentiments_df1 = load_sentiment_data(path)\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: {stock}, {e}\")\n",
    "        sentiments_df1 = None\n",
    "    try:\n",
    "        # Load sentiment and stock data\n",
    "        sentiments_df2 = load_sentiment_data(path2)\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: {stock}, {e}\")\n",
    "        sentiments_df2 = None\n",
    "        \n",
    "    if sentiments_df1 is not None and sentiments_df2 is None:\n",
    "        sentiments_df = sentiments_df1\n",
    "    elif sentiments_df1 is None and sentiments_df2 is not None:\n",
    "        sentiments_df = sentiments_df2\n",
    "    elif sentiments_df1 is None and sentiments_df2 is None:\n",
    "        continue\n",
    "    else:\n",
    "        sentiments_df = pd.concat([sentiments_df1, sentiments_df2])\n",
    "    stock_df = load_stock_data(stock)\n",
    "\n",
    "    if stock_df is None:\n",
    "        continue\n",
    "\n",
    "    # Merge sentiment and stock data\n",
    "    merged_df = pd.merge(stock_df, sentiments_df, on='Date', suffixes=('_yt', '_sentiments'), how='left')\n",
    "    merged_df = calculate_technical_indicators(merged_df)\n",
    "\n",
    "    # Encode Stock Symbol\n",
    "    merged_df['symbol'] = stock\n",
    "    merged_dfs.append(merged_df)\n",
    "# Merge all stock data\n",
    "merged_df = pd.concat(merged_dfs, ignore_index=True)\n",
    "merged_df = add_time_step_from_date(merged_df)\n",
    "\n",
    "original_datetime = merged_df['Date']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write out processed training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T06:16:16.545595Z",
     "iopub.status.busy": "2025-03-28T06:16:16.545205Z",
     "iopub.status.idle": "2025-03-28T06:16:26.263964Z",
     "shell.execute_reply": "2025-03-28T06:16:26.262946Z",
     "shell.execute_reply.started": "2025-03-28T06:16:16.545567Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "merged_df.to_csv(f\"{datetime.today()}_historical.csv\")\n",
    "merged_df.sample(30)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6822583,
     "sourceId": 10965781,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6822609,
     "sourceId": 10965818,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6847670,
     "sourceId": 11000138,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6872591,
     "sourceId": 11034211,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
