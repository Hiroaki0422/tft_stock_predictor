{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10965781,"sourceType":"datasetVersion","datasetId":6822583},{"sourceId":10965818,"sourceType":"datasetVersion","datasetId":6822609},{"sourceId":11000138,"sourceType":"datasetVersion","datasetId":6847670},{"sourceId":11034211,"sourceType":"datasetVersion","datasetId":6872591}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Feature Engineering Training Data","metadata":{}},{"cell_type":"markdown","source":"### Install Dependencies","metadata":{}},{"cell_type":"code","source":"pip install yfinance --upgrade --no-cache-dir","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import yfinance as yf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-28T06:09:41.214801Z","iopub.execute_input":"2025-03-28T06:09:41.215216Z","iopub.status.idle":"2025-03-28T06:09:41.220582Z","shell.execute_reply.started":"2025-03-28T06:09:41.215180Z","shell.execute_reply":"2025-03-28T06:09:41.219166Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Fetch Stock Data","metadata":{}},{"cell_type":"code","source":"# top 50-100 publicly traded companies\nsp50_tickers = [\n    'AAPL', 'ABBV', 'ABT', 'ACN', 'ADBE', 'AIG', 'AMD', 'AMGN', 'AMT', 'AMZN',\n    'AVGO', 'AXP', 'BA', 'BAC', 'BK', 'BKNG', 'BLK', 'BRK.B', 'C',\n    'CAT', 'CHTR', 'CL', 'CMCSA', 'COF', 'COP', 'COST', 'CRM', 'CSCO', 'CVS',\n    'CVX', 'DE', 'DHR', 'DIS', 'DOW', 'DUK', 'EMR', 'F', 'FDX', 'GD', 'GE',\n    'GILD', 'GM', 'GOOG', 'GOOGL', 'GS', 'HD', 'HON', 'IBM', 'INTC', 'INTU',\n    'JNJ', 'JPM', 'KHC', 'KO', 'LIN', 'LLY', 'LMT', 'LOW', 'MA', 'MCD',\n    'MDLZ', 'MDT', 'MET', 'META', 'MMM', 'MO', 'MRK', 'MS', 'MSFT', 'NEE',\n    'NFLX', 'NKE', 'NVDA', 'ORCL', 'PEP', 'PFE', 'PG', 'PM', 'PYPL', 'QCOM',\n    'RTX', 'SBUX', 'SCHW', 'SO', 'SPG', 'T', 'TGT', 'TMO', 'TMUS', 'TSLA',\n    'TXN', 'UNH', 'UNP', 'UPS', 'USB', 'V', 'VZ', 'WFC', 'WMT', 'XOM'\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-28T06:09:42.020272Z","iopub.execute_input":"2025-03-28T06:09:42.020683Z","iopub.status.idle":"2025-03-28T06:09:42.028655Z","shell.execute_reply.started":"2025-03-28T06:09:42.020648Z","shell.execute_reply":"2025-03-28T06:09:42.027414Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Indexes helpful to predict stock, key is API symbol for each index\nindicators = {\"^IXIC\": \"NASDAQ\", \n              \"^GSPC\": \"SNP\", \n              \"^DJI\": \"DJI\", \n              \"^RUT\": \"RUT\", \n              \"^VIX\": \"VIX\", \n              \"XLK\": \"XLK\",\n              \"XLE\": \"XLE\",\n              \"XLF\": \"XLF\",\n              \"XLV\": \"XLV\"\n             }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-28T06:09:43.524964Z","iopub.execute_input":"2025-03-28T06:09:43.525340Z","iopub.status.idle":"2025-03-28T06:09:43.530629Z","shell.execute_reply.started":"2025-03-28T06:09:43.525307Z","shell.execute_reply":"2025-03-28T06:09:43.529431Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create dataframe of important stock index\nindicator_df = None\nfor symbol in indicators:\n    ticker = yf.Ticker(symbol)\n    stock_df = ticker.history(period='10y', interval='1d').reset_index()\n    stock_df.head()\n    stock_df = stock_df.rename(columns={\n        'Open': indicators[symbol]\n    })\n    stock_df = stock_df[['Date', indicators[symbol]]]\n    stock_df['Date'] = stock_df['Date'].dt.date\n    \n    if indicator_df is None:\n        indicator_df = stock_df.copy()\n        continue\n    indicator_df = indicator_df.merge(stock_df, how='inner', on=['Date'])\nindicator_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-28T06:09:45.860148Z","iopub.execute_input":"2025-03-28T06:09:45.860474Z","iopub.status.idle":"2025-03-28T06:09:47.174760Z","shell.execute_reply.started":"2025-03-28T06:09:45.860450Z","shell.execute_reply":"2025-03-28T06:09:47.173204Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ================================\n# ðŸ“Œ Load and Process Stock Data\n# ================================\ndef load_stock_data(ticker_symbol, indicators=indicator_df):\n    \"\"\"Fetches stock data from Yahoo Finance and processes it for merging.\"\"\"\n    print(f\"loading {ticker_symbol}\")\n    ticker = yf.Ticker(ticker_symbol)\n    stock_df = ticker.history(period='10y', interval='1d').reset_index()\n    try:\n        stock_df['month'] = stock_df['Date'].dt.month\n        stock_df['day'] = stock_df['Date'].dt.day\n        stock_df['day_of_week'] = stock_df['Date'].dt.dayofweek\n        stock_df['Date'] = stock_df['Date'].dt.date\n        stock_df = stock_df.merge(indicators, how='left', on=['Date'])\n    except Exception as e:\n        print(e)\n        stock_df = None\n    return stock_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-28T06:14:31.534975Z","iopub.execute_input":"2025-03-28T06:14:31.535352Z","iopub.status.idle":"2025-03-28T06:14:31.542325Z","shell.execute_reply.started":"2025-03-28T06:14:31.535325Z","shell.execute_reply":"2025-03-28T06:14:31.540870Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test = load_stock_data('AAPL')\ntest.sample(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-28T06:14:37.744773Z","iopub.execute_input":"2025-03-28T06:14:37.745149Z","iopub.status.idle":"2025-03-28T06:14:38.001710Z","shell.execute_reply.started":"2025-03-28T06:14:37.745120Z","shell.execute_reply":"2025-03-28T06:14:38.000477Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Feature Engineering","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport yfinance as yf\nimport tensorflow as tf\nfrom sklearn.preprocessing import MinMaxScaler\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import LSTM, Dense, Dropout, Embedding, Input, Concatenate\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.simplefilter(action='ignore', category=RuntimeWarning)\n\n# ================================\n# ðŸ“Œ Load and Process Sentiment Data\n# ================================\ndef load_sentiment_data(file_path):\n    \"\"\"Loads and processes sentiment data, aggregates sentiment scores by date.\"\"\"\n    sentiment_map = {'positive': 1, 'neutral': 0, 'negative': -1}\n    \n    df = pd.read_csv(file_path)\n    df['sentiment_mapped'] = df['sentiment'].map(sentiment_map)\n    df['Date'] = pd.to_datetime(df['Date']).dt.date  # Convert to date (no time)\n\n    # Aggregate sentiment scores by date\n    sentiment_sum = df.groupby('Date', as_index=False)['sentiment_mapped'].sum()\n    sentiment_count = df.groupby('Date', as_index=False)['sentiment_mapped'].count()\n    sentiment_sum['sentiment'] = sentiment_sum['sentiment_mapped'] / sentiment_count['sentiment_mapped']\n\n    return sentiment_sum[['Date', 'sentiment']]\n\n# ================================\n# ðŸ“Œ Compute Technical Indicators\n# ================================\ndef calculate_technical_indicators(df):\n    \"\"\"Computes RSI, Moving Averages, Log Returns, and Realized Volatility.\"\"\"\n    def calculate_rsi(data, column='Close', period=14):\n        delta = data[column].diff()\n        gains = delta.where(delta > 0, 0)\n        losses = -delta.where(delta < 0, 0)\n        avg_gain = gains.rolling(window=period, min_periods=1).mean()\n        avg_loss = losses.rolling(window=period, min_periods=1).mean()\n        rs = avg_gain / avg_loss\n        return 100 - (100 / (1 + rs))\n\n    df['RSI'] = calculate_rsi(df, column='Close')\n\n    # Moving Averages\n    for ma in [20, 50, 200]:\n        df[f'MA_{ma}'] = df['Close'].rolling(window=ma).mean()\n    \n    # Log Returns\n    df['log_return'] = np.log(df['Close'] / df['Close'].shift(1))\n\n    # Realized Volatility\n    for rv in [20, 50]:\n        df[f'RV_{rv}'] = df['log_return'].rolling(window=rv).std() * np.sqrt(252)\n    \n    return df  # Drop NaN values from rolling calculations\n\n# ================================\n# ðŸ“Œ Create time step\n# ================================\ndef add_time_step_from_date(df, date_column='Date', step_column='time_idx'):\n    \"\"\"\n    Adds a TimeStep column to the DataFrame where each unique date gets\n    a unique, increasing integer starting from 0. Duplicate dates share the same time step.\n\n    Parameters:\n    - df (pd.DataFrame): Input DataFrame with a date column.\n    - date_column (str): Name of the date column.\n    - step_column (str): Name of the time step column to add.\n\n    Returns:\n    - pd.DataFrame: DataFrame with an added time step column.\n    \"\"\"\n    df[date_column] = pd.to_datetime(df[date_column])\n    unique_dates = pd.Series(df[date_column].sort_values().unique())\n    date_to_step = {date: i for i, date in enumerate(unique_dates)}\n    df[step_column] = df[date_column].map(date_to_step)\n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-28T06:15:05.094929Z","iopub.execute_input":"2025-03-28T06:15:05.095287Z","iopub.status.idle":"2025-03-28T06:15:05.111049Z","shell.execute_reply.started":"2025-03-28T06:15:05.095259Z","shell.execute_reply":"2025-03-28T06:15:05.109657Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ================================\n# ðŸ“Œ Main Processing for Multiple Stocks\n# ================================\npaths = ['/kaggle/input/aapl-sentiments/AAPL.csv', '/kaggle/input/stock-sentiments/ABBV.csv']\nmerged_dfs = []\n\nfor stock in sp50_tickers:\n    path = \"/kaggle/input/sentiments-history/\" + stock + \".csv\"\n    path2 = \"/kaggle/input/sentiments2/\" + stock + \".csv\"\n    try:\n        # Load sentiment and stock data\n        sentiments_df1 = load_sentiment_data(path)\n    except Exception as e:\n        print(f\"ERROR: {stock}, {e}\")\n        sentiments_df1 = None\n    try:\n        # Load sentiment and stock data\n        sentiments_df2 = load_sentiment_data(path2)\n    except Exception as e:\n        print(f\"ERROR: {stock}, {e}\")\n        sentiments_df2 = None\n        \n    if sentiments_df1 is not None and sentiments_df2 is None:\n        sentiments_df = sentiments_df1\n    elif sentiments_df1 is None and sentiments_df2 is not None:\n        sentiments_df = sentiments_df2\n    elif sentiments_df1 is None and sentiments_df2 is None:\n        continue\n    else:\n        sentiments_df = pd.concat([sentiments_df1, sentiments_df2])\n    stock_df = load_stock_data(stock)\n\n    if stock_df is None:\n        continue\n\n    # Merge sentiment and stock data\n    merged_df = pd.merge(stock_df, sentiments_df, on='Date', suffixes=('_yt', '_sentiments'), how='left')\n    merged_df = calculate_technical_indicators(merged_df)\n\n    # Encode Stock Symbol\n    merged_df['symbol'] = stock\n    merged_dfs.append(merged_df)\n# Merge all stock data\nmerged_df = pd.concat(merged_dfs, ignore_index=True)\nmerged_df = add_time_step_from_date(merged_df)\n\noriginal_datetime = merged_df['Date']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-28T06:15:08.885203Z","iopub.execute_input":"2025-03-28T06:15:08.885541Z","iopub.status.idle":"2025-03-28T06:15:36.412860Z","shell.execute_reply.started":"2025-03-28T06:15:08.885513Z","shell.execute_reply":"2025-03-28T06:15:36.411736Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Write out processed training data","metadata":{}},{"cell_type":"code","source":"from datetime import datetime\nmerged_df.to_csv(f\"{datetime.today()}_historical.csv\")\nmerged_df.sample(30)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-28T06:16:16.545205Z","iopub.execute_input":"2025-03-28T06:16:16.545595Z","iopub.status.idle":"2025-03-28T06:16:26.263964Z","shell.execute_reply.started":"2025-03-28T06:16:16.545567Z","shell.execute_reply":"2025-03-28T06:16:26.262946Z"}},"outputs":[],"execution_count":null}]}